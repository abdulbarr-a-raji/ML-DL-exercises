{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbSsaFzHcK48aOSZE2AeJN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"txq65tJC7cOe"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","source":["class Generator(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(Generator, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, output_size)\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.tanh(self.fc2(x))\n","        return x\n","\n","\n"],"metadata":{"id":"yYtnImSr7wwU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(Discriminator, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, output_size)\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.sigmoid(self.fc2(x))\n","        return x"],"metadata":{"id":"NAeDR5xd8BgL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Set the input and output sizes\n","input_size = 784\n","hidden_size = 256\n","output_size = 1\n","\n","# Create the discriminator and generator\n","discriminator = Discriminator(input_size, hidden_size, output_size).to(device)\n","generator = Generator(input_size, hidden_size, output_size).to(device)\n","\n","# Set the loss function and optimizers\n","loss_fn = nn.BCEWithLogitsLoss()\n","d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n","g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002)\n","\n","# Set the number of epochs and the noise size\n","num_epochs = 200\n","noise_size = 100\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","  for i, (real_images, _) in enumerate(dataloader):\n","    # Get the batch size\n","    batch_size = real_images.size(0)"],"metadata":{"id":"OdfaZ-aA8CM1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate fake images\n","  noise = torch.randn(batch_size, noise_size).to(device)\n","  fake_images = generator(noise)\n","\n","  # Train the discriminator on real and fake images\n","  d_real = discriminator(real_images)\n","  d_fake = discriminator(fake_images)\n","\n","  # Calculate the loss\n","  real_loss = loss_fn(d_real, torch.ones_like(d_real))\n","  fake_loss = loss_fn(d_fake, torch.zeros_like(d_fake))\n","  d_loss = real_loss + fake_loss\n","\n","  # Backpropagate and optimize\n","  d_optimizer.zero_grad()\n","  d_loss.backward()\n","  d_optimizer.step()\n","\n","  # Train the generator\n","  d_fake = discriminator(fake_images)\n","  g_loss = loss_fn(d_fake, torch.ones_like(d_fake))\n","\n","  # Backpropagate and optimize\n","  g_optimizer.zero_grad()\n","  g_loss.backward()\n","  g_optimizer.step()\n","\n","  # Print the loss every 50 batches\n","  if (i+1) % 50 == 0:\n","    print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}'\n","          .format(epoch+1, num_epochs, i+1, len(dataloader), d_loss.item(), g_loss.item()))"],"metadata":{"id":"i-rVWeOv8QlJ"},"execution_count":null,"outputs":[]}]}